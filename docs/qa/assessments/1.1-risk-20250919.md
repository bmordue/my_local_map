# Risk Assessment: Story 1.1 - Expand Geographic Coverage

## Executive Summary

This story introduces the capability to generate maps for multiple areas in Aberdeenshire, expanding beyond the initial Lumsden area. The implementation is well-structured and follows good practices. The primary risks identified are related to test coverage and potential reliability issues from failing integration tests.

## Risk Matrix

| Risk ID | Category       | Description                                                                 | Probability | Impact | Risk Score | Mitigation Strategy                                                  |
| :------ | :------------- | :-------------------------------------------------------------------------- | :---------- | :----- | :--------- | :------------------------------------------------------------------- |
| R001    | Reliability    | Failing integration tests indicate potential issues in the main application flow | Medium      | High   | 15         | Investigate and fix the failing tests to ensure application stability |
| R002    | Maintainability| Test suite has warnings about unknown pytest marks                          | Low         | Low    | 1          | Address pytest warnings by properly registering custom marks         |
| R003    | Performance    | Map generation time may vary significantly based on area size and data complexity | Low         | Medium | 6          | Monitor generation times and optimize data processing as needed      |

## Detailed Risk Analysis

### R001: Failing Integration Tests (Score: 15)

**Description:** Three integration tests in `tests/test_integration.py` are failing due to a `KeyError: 'name'` when trying to access `area_config['name']` in the `main` function. This indicates a mismatch between the test setup and the actual implementation.

**Impact:** High - This could indicate a real bug in the application that might cause it to crash when generating maps for areas other than Lumsden if the area configuration doesn't include a 'name' field.

**Probability:** Medium - The issue is reproducible in tests, suggesting it's likely to occur in certain real-world scenarios.

**Mitigation:**
1. Update the test cases to include the 'name' field in the mocked `area_config`.
2. Verify that all area configurations in `config/areas.json` include the 'name' field.
3. Add a check in `map_generator.py` to handle cases where the 'name' field might be missing.

### R002: Pytest Warnings (Score: 1)

**Description:** The test suite produces warnings about unknown pytest marks (`unit` and `integration`).

**Impact:** Low - These are warnings and don't affect the functionality, but they indicate a lack of proper test configuration.

**Probability:** High - These warnings appear consistently in all test runs.

**Mitigation:**
1. Register the custom marks in `pytest.ini` to eliminate the warnings.

### R003: Variable Map Generation Performance (Score: 6)

**Description:** Map generation time depends on external services (Overpass API) and local processing (GDAL), which can vary significantly.

**Impact:** Medium - Users might experience inconsistent wait times for map generation.

**Probability:** Low - Performance is generally acceptable, but could degrade with larger areas or complex data.

**Mitigation:**
1. Monitor generation times during usage.
2. Consider implementing progress indicators for long-running operations.
3. Optimize data processing steps where possible.

## Recommendations

1.  **Immediate:** Fix the failing integration tests by ensuring the test setup matches the actual configuration structure.
2.  **Short-term:** Address pytest warnings by properly configuring custom marks.
3.  **Long-term:** Monitor map generation performance and optimize as needed.